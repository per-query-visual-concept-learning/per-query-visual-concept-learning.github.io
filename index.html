<!DOCTYPE html>
<html lang="en">
<head>
  <!-- Metadata and links omitted for brevity -->
  <style>
    .title-centered {
      text-align: center;
    }
    .image-centered {
  display: block;
  margin-left: auto;
  margin-right: auto;
  width: 100%; /* Increased width for larger image */
}
    .image-bigger {
  display: block;
  margin-left: auto;
  margin-right: auto;
  width: 80%; /* Increased width for larger image */
}
.image-half-width {
  display: block;
  margin-left: auto;
  margin-right: auto;
  width: 80%; /* Set width to 50% */
}
    .image-smaller {
  display: block;
  margin-left: auto;
  margin-right: auto;
  width: 30%; /* Set width to 50% */
}
.content-centered {
  text-align: justify; /* Aligns text like the abstract */
  font-size: 1rem; /* Matches the abstract font size */
}


.conference-tag p {
  text-align: center;
  font-size: 2em;  /* Matching the h1 size */
  font-weight: bold;  /* Assuming you want it bold like a title */
  margin-top: 10px;
  margin-bottom: 20px;
}




.section {
  background-color: #f5f5f5; /* Consistent background like the abstract */
}
    .subtitle {
      margin-top: 20px; /* Adds space between image and text */
      font-size: 1rem; /* Matches the abstract font size */
    }
    .light-section {
      background-color: #f5f5f5; /* Light gray background */
    }
    .dark-section {
      background-color: #ffffff; /* White background */
    }
  </style>
</head>
<body>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Per Query Visual Concept Learning">
  <meta name="keywords" content="">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Per Query Visual Concept Learning</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Per Query Visual Concept Learning</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://github.com/Orimalca/">Ori Malca</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=_CWxQ1gAAAAJ">Dvir Samuel</a><sup>1,2</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=Wk2gAZUAAAAJ">Gal Chechik</a><sup>1,3</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Bar-Ilan University,</span>
            <span class="author-block"><sup>2</sup>OriginAI,</span>
            <span class="author-block"><sup>3</sup>NVIDIA</span>

          </div>

          <!-- <div class="conference-tag">
            <p>WACV 2026</p>
          </div> -->

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org/abs/0000.00000"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/Orimalca/pq_learning"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/imgs/fig1.png" class="image-centered">
      <h2 class="subtitle has-text-centered">
        Given a pretrained text-to-image personalization checkpoint, our method enhances per-query generation in terms of image alignment and text alignment, with just a single gradient update (~4 seconds on an NVIDIA H100 GPU). It is compatible with a wide range of personalization techniques (e.g., DreamBooth, LoRA, Textual Inversion, DBlend) and supports various diffusion backbones, including UNet-based models (e.g., SDXL, SD) and transformer-based models (e.g., FLUX, SD3).
      </h2>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Visual concept learning, also known as Text-to-image personalization, is the process of teaching new concepts to a pretrained model. This has numerous applications from product placement to entertainment and personalized design. Here we show that many existing methods can be substantially augmented by adding a personalization step that is (1) specific to the prompt and noise seed, and (2) using two loss terms based on the self- and cross- attention, capturing the identity of the personalized concept. Specifically, we leverage PDM features - previously designed to capture identity - and show how they can be used to improve personalized semantic similarity. We evaluate the benefit that our method gains on top of six different personalization methods, and several base text-to-image models (both UNet- and DiT-based). We find significant improvements even over previous per-query personalization methods.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="hero is-light is-small">
  <div class="hero-body">
  <h2 class="title has-text-centered">Qualitative Comparisons</h2>
    <div class="container">
        <div id="results-carousel" class="carousel results-carousel">

          <div class="item item-steve">
          <img src="./static/imgs/qlc/vs_SOTA/models.png" style="width:100%">
          <img src="./static/imgs/qlc/vs_SOTA/1.0.png" style="width:100%">
          </div>

          <div class="item item-shiba">
          <img src="./static/imgs/qlc/vs_SOTA/models.png" style="width:100%">
          <img src="./static/imgs/qlc/vs_SOTA/1.1.png" style="width:100%;">
          </div>

          <div class="item item-shiba">
          <img src="./static/imgs/qlc/vs_SOTA/models.png" style="width:100%">
          <img src="./static/imgs/qlc/vs_SOTA/1.2.png" style="width:100%;">
          </div>

          <div class="item item-shiba">
          <img src="./static/imgs/qlc/vs_SOTA/models.png" style="width:100%">
          <img src="./static/imgs/qlc/vs_SOTA/1.3.png" style="width:100%;">
          </div>

          <div class="item item-shiba">
          <img src="./static/imgs/qlc/vs_SOTA/models.png" style="width:100%">
          <img src="./static/imgs/qlc/vs_SOTA/2.0.png" style="width:100%;">
          </div>

          <div class="item item-shiba">
          <img src="./static/imgs/qlc/vs_SOTA/models.png" style="width:100%">
          <img src="./static/imgs/qlc/vs_SOTA/2.1.png" style="width:100%;">
          </div>

          <div class="item item-shiba">
          <img src="./static/imgs/qlc/vs_SOTA/models.png" style="width:100%">
          <img src="./static/imgs/qlc/vs_SOTA/2.2.png" style="width:100%;">
          </div>

          <div class="item item-shiba">
          <img src="./static/imgs/qlc/vs_SOTA/models.png" style="width:100%">
          <img src="./static/imgs/qlc/vs_SOTA/2.3.png" style="width:100%;">
          </div>

          <div class="item item-shiba">
          <img src="./static/imgs/qlc/vs_SOTA/models.png" style="width:100%">
          <img src="./static/imgs/qlc/vs_SOTA/3.0.png" style="width:100%;">
          </div>

          <div class="item item-shiba">
          <img src="./static/imgs/qlc/vs_SOTA/models.png" style="width:100%">
          <img src="./static/imgs/qlc/vs_SOTA/3.1.png" style="width:100%;">
          </div>

          <div class="item item-shiba">
          <img src="./static/imgs/qlc/vs_SOTA/models.png" style="width:100%">
          <img src="./static/imgs/qlc/vs_SOTA/3.2.png" style="width:100%;">
          </div>

          <div class="item item-shiba">
          <img src="./static/imgs/qlc/vs_SOTA/models.png" style="width:100%">
          <img src="./static/imgs/qlc/vs_SOTA/3.3.png" style="width:100%;">
          </div>
        </div>

      <div class="content has-text-justified carousel-caption" style="margin-bottom: 1rem;">
        <p>
          We present images generated by various personalization methods without our method and with it, including DB, TI, DBlend, CLD, AttnDB, and LoRA, across 4 different backbones (FLUX, SDXL, SD2.1, SD1.5). The left column shows one example of the target concept, and then every pair of columns shows the generated images with and without our method. Each pair uses the same prompt and seed. Adding our method to those personalization approaches yields better performance in text alignment and identity preservation compared to these baselines. Prompts were generated using ChatGPT.
        </p>
      </div>
      
    </div>

    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
        <img src="./static/imgs/qlc/vs_PQ/methods.png" style="width:100%">
        <img src="./static/imgs/qlc/vs_PQ/1.0.png" style="width:100%;">
        <img src="./static/imgs/qlc/vs_PQ/models.png" style="width:100%">
        </div>

        <div class="item item-shiba">
        <img src="./static/imgs/qlc/vs_PQ/methods.png" style="width:100%">
        <img src="./static/imgs/qlc/vs_PQ/1.1.png" style="width:100%;">
        <img src="./static/imgs/qlc/vs_PQ/models.png" style="width:100%">
        </div>

        <div class="item item-shiba">
        <img src="./static/imgs/qlc/vs_PQ/methods.png" style="width:100%">
        <img src="./static/imgs/qlc/vs_PQ/1.2.png" style="width:100%;">
        <img src="./static/imgs/qlc/vs_PQ/models.png" style="width:100%">
        </div>

        <div class="item item-shiba">
        <img src="./static/imgs/qlc/vs_PQ/methods.png" style="width:100%">
        <img src="./static/imgs/qlc/vs_PQ/1.3.png" style="width:100%;">
        <img src="./static/imgs/qlc/vs_PQ/models.png" style="width:100%">
        </div>

        <div class="item item-shiba">
        <img src="./static/imgs/qlc/vs_PQ/methods.png" style="width:100%">
        <img src="./static/imgs/qlc/vs_PQ/2.0.png" style="width:100%;">
        <img src="./static/imgs/qlc/vs_PQ/models.png" style="width:100%">
        </div>

        <div class="item item-shiba">
        <img src="./static/imgs/qlc/vs_PQ/methods.png" style="width:100%">
        <img src="./static/imgs/qlc/vs_PQ/2.1.png" style="width:100%;">
        <img src="./static/imgs/qlc/vs_PQ/models.png" style="width:100%">
        </div>

        <div class="item item-shiba">
        <img src="./static/imgs/qlc/vs_PQ/methods.png" style="width:100%">
        <img src="./static/imgs/qlc/vs_PQ/2.2.png" style="width:100%;">
        <img src="./static/imgs/qlc/vs_PQ/models.png" style="width:100%">
        </div>

        <div class="item item-shiba">
        <img src="./static/imgs/qlc/vs_PQ/methods.png" style="width:100%">
        <img src="./static/imgs/qlc/vs_PQ/2.3.png" style="width:100%;">
        <img src="./static/imgs/qlc/vs_PQ/models.png" style="width:100%">
        </div>

        <div class="item item-shiba">
        <img src="./static/imgs/qlc/vs_PQ/methods.png" style="width:100%">
        <img src="./static/imgs/qlc/vs_PQ/3.0.png" style="width:100%;">
        <img src="./static/imgs/qlc/vs_PQ/models.png" style="width:100%">
        </div>

        <div class="item item-shiba">
        <img src="./static/imgs/qlc/vs_PQ/methods.png" style="width:100%">
        <img src="./static/imgs/qlc/vs_PQ/3.1.png" style="width:100%;">
        <img src="./static/imgs/qlc/vs_PQ/models.png" style="width:100%">
        </div>

        <div class="item item-shiba">
        <img src="./static/imgs/qlc/vs_PQ/methods.png" style="width:100%">
        <img src="./static/imgs/qlc/vs_PQ/3.2.png" style="width:100%;">
        <img src="./static/imgs/qlc/vs_PQ/models.png" style="width:100%">
        </div>

        <div class="item item-shiba">
        <img src="./static/imgs/qlc/vs_PQ/methods.png" style="width:100%">
        <img src="./static/imgs/qlc/vs_PQ/3.3.png" style="width:100%;">
        <img src="./static/imgs/qlc/vs_PQ/models.png" style="width:100%">
        </div>

      </div>
      <div class="content has-text-justified carousel-caption">
        <p>
          We present images generated by 3 personalization methods (including DB, TI, LoRA) using 3 per query methods (including AlignIT, PALP, Ours), across 3 different backbones (FLUX, SDXL, SD2.1). Our method demonstrates superior performance in text alignment and identity preservation compared to these per-query methods. Our per-query method, is the only method that successfully generates identity preserved and text-aligned personalized images for these complex queries.
        </p>
      </div>
    </div>
  </div>
</section>


<section class="architecture" style="margin-top: 4rem;">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 title-centered" style="margin-bottom: 0rem;">How does our method work?</h2>
        <div class="hero-body">
          <img src="./static/imgs/method.png" class="image-bigger" style="width:60%; margin: 0 auto;">
          <p class="content-centered" style="margin-top: 1rem;">
            We enhance personalized text-to-image models by computing self- and cross-attention features from a single denoising step of a generated image \( x^{\text{gen}} \) and a reference image \( x^{\text{ref}} \). Using DIFT, we match these features and define losses \( \mathcal{L}_{\text{SA}} \), \( \mathcal{L}_{\text{CA}} \), and \( \mathcal{L}_{\text{LDM}} \), which are combined to update the personalization tuning parameters via gradient descent.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="architecture">
  <div class="container">
    <h2 class="title is-3 title-centered" style="margin-bottom: 2.5rem; margin-top: 1rem;">Quantitative Comparisons</h2>
    <div class="columns is-centered has-text-centered" style="gap: 3rem;">
      <div class="column is-half">
        <img src="./static/imgs/qnc/vs_SOTA/SD2.1_CLIP-I.jpg" class="image-half-width" style="margin-right: 0;">
      </div>
      <div class="column is-half">
        <img src="./static/imgs/qnc/vs_SOTA/SD2.1_CLIP-T.jpg" class="image-half-width" style="margin-left: 0;">
      </div>
    </div>
    <div class="columns is-centered has-text-centered">
      <div class="column is-full text-aligned" style="padding-top: 0px; padding-bottom: 1rem;">
        <p class="content-centered">
          Effect of adding our method to baseline personalization models. shown are image alignment (left) and text alignment (right) of several personalization approaches with (w/) and without (w/o) the integration of our method.
        </p>
      </div>
    </div>

    <div class="columns is-centered has-text-centered" style="gap: 3rem;">
      <div class="column is-half">
        <img src="./static/imgs/qnc/vs_PQ/SD2.1_CLIP_I.jpg" class="image-half-width" style="margin-right: 0;">
      </div>
      <div class="column is-half">
        <img src="./static/imgs/qnc/vs_PQ/SD2.1_CLIP_T.jpg" class="image-half-width" style="margin-left: 0;">
      </div>
    </div>
    <div class="columns is-centered has-text-centered">
      <div class="column is-full text-aligned" style="padding-top: 0px; padding-bottom: 1rem;">
        <p class="content-centered">
          Quantitative Comparison with previous per-query methods. Image alignment (left) and text alignment (right) of various personalization approaches (including, DB, LoRA, and TI), with (w/) and without (w/o) the integration of different per-query methods (including, AlignIT, PALP, and Ours).
        </p>
      </div>
    </div>
  </div>
</section>

<section class="architecture">
  <div class="container">
    <h2 class="title is-3 title-centered" style="margin-bottom: 2.5rem; margin-top: 4rem;">Ablation Studies and Sensitivity to Parameters</h2>
    <div class="columns is-centered has-text-centered" style="gap: 3rem;">
      <div class="column is-half">
        <img src="./static/imgs/ablations/time_ablations/ts_opt1/SD2.1_CLIP-I.jpg" class="image-half-width" style="margin-right: 0;">
      </div>
      <div class="column is-half">
        <img src="./static/imgs/ablations/time_ablations/ts_opt1/SD2.1_CLIP-T.jpg" class="image-half-width" style="margin-left: 0;">
      </div>
    </div>
    <div class="columns is-centered has-text-centered">
      <div class="column is-full text-aligned" style="padding-top: 0px; padding-bottom: 1rem;">
        <p class="content-centered">
          <strong>Quality-vs-time Tradeoff.</strong>&nbsp;&nbsp;&nbsp;&nbsp;Figures show the CLIP-I (left) and CLIP-T (right) metrics as a function of fine-tuning duration. The duration is longer when using more features that are collected throughout the denoising path. \( T \) is the number of feature maps using to compute the losses.
        </p>
      </div>
    </div>

    <div class="columns is-centered has-text-centered" style="gap: 3rem;">
      <div class="column is-half">
        <img src="./static/imgs/ablations/time_ablations/ts_opt2/SD2.1_CLIP-I.jpg" class="image-half-width" style="margin-right: 0;">
      </div>
      <div class="column is-half">
        <img src="./static/imgs/ablations/time_ablations/ts_opt2/SD2.1_CLIP-T.jpg" class="image-half-width" style="margin-left: 0;">
      </div>
    </div>
    <div class="columns is-centered has-text-centered">
      <div class="column is-full text-aligned" style="padding-top: 0px; padding-bottom: 1rem;">
        <p class="content-centered">
          <strong>Quality-vs-time Tradeoff.</strong>&nbsp;&nbsp;&nbsp;&nbsp;Figures show the CLIP-I (left) and CLIP-T (right) metrics as a function of fine-tuning duration. The duration is longer when using more SA features that are collected throughout the denoising path. \( T \) is the number of feature maps using to compute the losses.
        </p>
      </div>
    </div>

    <div class="columns is-centered has-text-centered" style="gap: 3rem;">
      <div class="column is-half">
        <img src="./static/imgs/ablations/ts_ablation_plot/SD2.1_CLIP-I.jpg" class="image-half-width" style="margin-right: 0;">
      </div>
      <div class="column is-half">
        <img src="./static/imgs/ablations/ts_ablation_plot/SD2.1_CLIP-T.jpg" class="image-half-width" style="margin-left: 0;">
      </div>
    </div>
    <div class="columns is-centered has-text-centered">
      <div class="column is-full text-aligned" style="padding-top: 0px; padding-bottom: 1rem;">
        <p class="content-centered">
            <strong>Noise weight Ablation Study.</strong>&nbsp;&nbsp;&nbsp;&nbsp;Sensitivity of CLIP-I and CLIP-T metrics to the magnitude of the noise, in terms of the \( t \) parameter used when calculating features.
        </p>
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-half">
        <img src="./static/imgs/ablations/tables/per-loss_contribution_ablation_study.png" class="image-half-width" style="width: 100%; margin-bottom: 0rem;">
      </div>
    </div>
    <div class="columns is-centered has-text-centered">
      <div class="column is-full text-aligned" style="padding-top: 0px; padding-bottom: 1rem;">
        <p class="content-centered">
          <strong>Per-loss contribution ablation study.</strong>&nbsp;&nbsp;&nbsp;&nbsp;We investigate the contribution of each loss in our proposed method. Testing across different methods, leveraging SD1.5 as backbone, and using a fixed \( \lambda_{\text{PDM}}=1,\lambda_{\text{CA}}=1 \) values. \( \mathcal{L}_{\text{PDM}} \) provides superior subject alignment, and \( \mathcal{L}_{\text{CA}} \) results superior prompt-adherence. Incorporating both provides superior results in both aspects.
        </p>
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-half">
        <img src="./static/imgs/ablations/tables/stage-wise_loss_effectiveness_ablation_study.png" class="image-half-width" style="width: 100%; margin-bottom: 0rem;">
      </div>
    </div>
    <div class="columns is-centered has-text-centered">
      <div class="column is-full text-aligned" style="padding-top: 0px; padding-bottom: 1rem;">
        <p class="content-centered">
          <strong>Stage-wise loss effectiveness ablation study.</strong>&nbsp;&nbsp;&nbsp;&nbsp;We examine the effectiveness of \( \mathcal{L}_{\text{SA}} \) and \( \mathcal{L}_{\text{CA}} \) throughout training rather than post-training, with two prominent methods, utilizing SD1.5 as backbone, with \( \lambda_{\text{PDM}}=1,\lambda_{\text{CA}}=1 \). We observe inferior results compared to post-training integration, and equal/inferior results compared to the baseline. This quantitatively support that certain losses become effective only after the model reaches a certain state.
        </p>
      </div>
    </div>

  </div>
</section>

<section class="architecture">
    <br>
  <div class="container is-max-desktop" style="margin-bottom: 32px;">
    <h2 class="title">BibTeX</h2>
    <p>If you find our work useful, please cite our paper:</p>
    <pre style="padding: 0%; text-align: left;">
    <code>
    @article{malca2024perquery,
      title   = {Per Query Visual Concept Learning},
      author  = {Malca, Ori and Samuel, Dvir and Chechik, Gal},
      journal = {arXiv preprint arXiv:0000.00000},
      year    = {2026}
    }
    </code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
             Website source code based on the <a
              href="https://nerfies.github.io/">Nerfies</a> project page. If you want to reuse their <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> , please credit them appropriately.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>




</body>
</html>